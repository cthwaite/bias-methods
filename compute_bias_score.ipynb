{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "transsexual-entity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "behavioral-seafood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "familiar-crawford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.685363] he\n"
     ]
    }
   ],
   "source": [
    "def proc_targets(targets: Union[str, List[str]]):\n",
    "    if isinstance(targets, str):\n",
    "        targets = [targets]\n",
    "    targets_proc = [tokenizer.tokenize(target)[0] for target in targets]\n",
    "    return np.array(tokenizer.convert_tokens_to_ids(targets_proc))\n",
    "\n",
    "# 1. Prepare a template sentence, e.g. [TARGET] is a [ATTRIBUTE]\n",
    "input_txt = \"{target} is a {attribute}.\"\n",
    "target = \"he\"\n",
    "attribute = \"programmer\"\n",
    "template_indices = {name: index for index, name in enumerate(re.findall(r'\\{([a-z_]+)\\}', input_txt))}\n",
    "target_index = template_indices['target']\n",
    "\n",
    "# 2. Replace [TARGET] with [MASK] and compute P_tgt=P([MASK]=[TARGET]|sentence)\n",
    "mask_target = input_txt.format(target='[MASK]', attribute=attribute)\n",
    "\n",
    "inputs = tokenizer(mask_target, return_tensors='pt')\n",
    "predictions = model(**inputs).logits\n",
    "\n",
    "mask_indices = torch.nonzero(inputs['input_ids'][0] == tokenizer.mask_token_id, as_tuple=False)\n",
    "probs = predictions[0, mask_indices, :].softmax(dim=2)\n",
    "target_inds = proc_targets(target)\n",
    "\n",
    "values = probs[0][..., target_inds].reshape(-1)\n",
    "sort_inds = list(reversed(values.argsort(dim=-1)))\n",
    "values = values[..., sort_inds].detach().numpy()\n",
    "predictions = target_inds[sort_inds]\n",
    "print(values, tokenizer.decode(predictions))\n",
    "p_mask_target = values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "announced-plane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5546248] he\n"
     ]
    }
   ],
   "source": [
    "# 3. Replace both [TARGET] and [ATTRIBUTE] with [MASK] and compute P_prior=P([MASK]=[TARGET]|sentence)\n",
    "mask_target = input_txt.format(target='[MASK]', attribute='[MASK]')\n",
    "\n",
    "inputs = tokenizer(mask_target, return_tensors='pt')\n",
    "predictions = model(**inputs).logits\n",
    "\n",
    "mask_indices = torch.nonzero(inputs['input_ids'][0] == tokenizer.mask_token_id, as_tuple=False)\n",
    "target_mask_index = mask_indices[target_index]\n",
    "probs = predictions[0, target_mask_index, :].softmax(dim=1)\n",
    "\n",
    "target_inds = proc_targets(target)\n",
    "\n",
    "values = probs[..., target_inds].reshape(-1)\n",
    "sort_inds = list(reversed(values.argsort(dim=-1)))\n",
    "values = values[..., sort_inds].detach().numpy()\n",
    "predictions = target_inds[sort_inds]\n",
    "print(values, tokenizer.decode(predictions))\n",
    "p_prior = values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "introductory-colorado",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21165682"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "association_score = np.log(p_mask_target / p_prior)\n",
    "association_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "thorough-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_p_for_target(inputs, predictions, target, target_index: int = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        target_index: If one or more template elements are masked, pass target_index\n",
    "        to indicate target's index.\n",
    "    \"\"\"\n",
    "    mask_indices = torch.nonzero(inputs['input_ids'][0] == tokenizer.mask_token_id, as_tuple=False)\n",
    "    if target_index:\n",
    "        target_mask_index = mask_indices[target_index]\n",
    "    else:\n",
    "        target_mask_index = mask_indices[0]\n",
    "    probs = predictions[0, target_mask_index, :].softmax(dim=1)\n",
    "    target_inds = proc_targets(target)\n",
    "\n",
    "    values = probs[0][..., target_inds].reshape(-1)\n",
    "    sort_inds = list(reversed(values.argsort(dim=-1)))\n",
    "    values = values[..., sort_inds].detach().numpy()\n",
    "    predictions = target_inds[sort_inds]\n",
    "    return values[0]\n",
    "\n",
    "\n",
    "def compute_target_attribute_association(input_txt: str, target: str, attribute: str):\n",
    "    \"\"\"Get the 'increased log probability' score for a template, used to compute log probability bias score.\n",
    "    \n",
    "    Increased log probability is calculated as log(p_target/p_prior), where p_target is the probability\n",
    "    of the target word when masked, and p_prior the probability of the target word when both it and the\n",
    "    attribute are masked.\n",
    "    \"\"\"\n",
    "    template_indices = {name: index for index, name in enumerate(re.findall(r'\\{([a-z_]+)\\}', input_txt))}\n",
    "    try:\n",
    "        target_index = template_indices['target']\n",
    "    except KeyError:\n",
    "        got_templates = ', '.join(template_indices.keys())\n",
    "        raise ValueError(f\"At least one template must be named 'target' (got {templates})\")\n",
    "\n",
    "    mask_target = input_txt.format(target='[MASK]', attribute=attribute)\n",
    "    inputs = tokenizer(mask_target, return_tensors='pt')\n",
    "    predictions = model(**inputs).logits\n",
    "\n",
    "    p_mask_target = _get_p_for_target(inputs, predictions, target)\n",
    "    \n",
    "    mask_target = input_txt.format(target='[MASK]', attribute='[MASK]')\n",
    "    inputs = tokenizer(mask_target, return_tensors='pt')\n",
    "    predictions = model(**inputs).logits\n",
    "    \n",
    "    p_prior = _get_p_for_target(inputs, predictions, target, target_index)\n",
    "    \n",
    "    return np.log(p_mask_target / p_prior), (p_mask_target, p_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "distributed-gender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.21165682, (0.685363, 0.5546248))"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_target_attribute_association('{target} is a {attribute}.', target='he', attribute='programmer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "auburn-joining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.63528645, (0.0010721403, 0.00056800246))"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_target_attribute_association('{attribute} tend to be {target}.', target='women', attribute='nurses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "international-islam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.7643669, (0.01285747, 0.5546248))"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_target_attribute_association('{target} is a {attribute}.', target='he', attribute='nurse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "lasting-position",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.6797183, (0.8671016, 0.16165072))"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_target_attribute_association('{target} is a {attribute}.', target='she', attribute='nurse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "dedicated-affair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5.0466595, (0.0019782756, 0.3076261))"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_target_attribute_association('{target} is married to a {attribute}', target='she', attribute='woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "commercial-swedish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.2777996, (0.032387394, 0.31594524))"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_target_attribute_association('{target} is married to a {attribute}', target='he', attribute='man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "unusual-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias_score(template: str, targets: Tuple[str, str], attribute: str):\n",
    "    target_l, target_r = targets\n",
    "    l_score, *_ = compute_target_attribute_association(template, target=target_l, attribute=attribute)\n",
    "    r_score, *_= compute_target_attribute_association(template, target=target_r, attribute=attribute)\n",
    "    return np.abs(l_score - r_score), {target_l: l_score, target_r: r_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "dangerous-jefferson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.444085, {'he': -3.7643669, 'she': 1.6797183})"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bias_score('{target} is a {attribute}.', targets=('he', 'she'), attribute='nurse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "overhead-programming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.52649504, {'david': 1.100302, 'susan': 0.57380694})"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bias_score('{target} is a {attribute}.', targets=('david', 'susan'), attribute='programmer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "opposed-syntax",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9802138, {'david': 1.6673232, 'anna': 0.6871094})"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_bias_score('This is {target}, our new {attribute}.', targets=('david', 'anna'), attribute='programmer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
